import pandas as pd
import json 
import os

print(os.listdir("analysing_vulnerability_data/input_data/"))

with open("analysing_vulnerability_data/input_data/list_of_files.json") as list_of_files:
    files = list_of_files.read()
json_files = json.loads(files)

df = pd.DataFrame(columns=['Target', 'Class', 'Type', 'VulnerabilityID', 'PkgID', 'PkgName',
       'InstalledVersion', 'FixedVersion', 'Status', 'SeveritySource',
       'PrimaryURL', 'Title', 'Description', 'Severity', 'References',
       'PublishedDate', 'LastModifiedDate', 'PkgIdentifier.PURL',
       'DataSource.ID', 'DataSource.Name', 'DataSource.URL',
       'VendorSeverity.ghsa', 'CVSS.ghsa.V3Vector', 'CVSS.ghsa.V3Score',
       'VendorSeverity.alma', 'VendorSeverity.amazon',
       'VendorSeverity.bitnami', 'VendorSeverity.oracle-oval',
       'VendorSeverity.redhat', 'VendorSeverity.rocky',
       'CVSS.bitnami.V3Vector', 'CVSS.bitnami.V3Score', 'CVSS.redhat.V3Vector',
       'CVSS.redhat.V3Score', 'VendorSeverity.ubuntu', 'CweIDs',
       'VendorSeverity.nvd', 'CVSS.nvd.V2Vector', 'CVSS.nvd.V3Vector',
       'CVSS.nvd.V2Score', 'CVSS.nvd.V3Score', 'sbom_name'])

# df = pd.DataFrame()

for each in json_files:
    with open(f"analysing_vulnerability_data/input_data/scanned_sboms/{each}") as file_to_open:
        data = file_to_open.read()
    json_data = json.loads(data)

    if "Results" in json_data:

        package_vulnerability_raw_data = json_data.get("Results")[0]
        vulnerability_to_df = pd.DataFrame(package_vulnerability_raw_data)
        vulnerability_df_filtered = vulnerability_to_df.map(lambda x: x[0] if isinstance(x, list) else x)

        df_dict = pd.json_normalize(vulnerability_to_df['Vulnerabilities'])
        df_final = vulnerability_to_df.drop('Vulnerabilities', axis=1).join(df_dict)

        df_final['sbom_name'] = json_data.get('ArtifactName').split('/')[-1]

        df = pd.concat([df, df_final], ignore_index=True)

simplified_df = df.filter([
    'VulnerabilityID', 
    'PkgID', 
    'PkgName', 
    'InstalledVersion', 
    'FixedVersion', 
    'SeveritySource',
    'PrimaryURL',
    'Title',
    'Description',
    'Severity',
    'CweIDs',
    'sbom_name'
    ], axis=1)

# Create patch recommendation document for CI/CD workflows to update repositories 


# Extract 'OrgName' and timestamp from 'sbom_name'
simplified_df[['OrgName', 'Timestamp']] = simplified_df['sbom_name'].str.extract(r'(.*).sbom-(.*)')

# Convert 'Timestamp' to datetime
simplified_df['Timestamp'] = pd.to_datetime(simplified_df['Timestamp'], format='%Y%m%d%H%M%S%f')

# Sort by 'OrgName' and 'Timestamp'
simplified_df = simplified_df.sort_values(['OrgName', 'Timestamp'])

# Drop duplicates based on 'OrgName', keeping only the last occurrence
simplified_df = simplified_df.drop_duplicates(subset='OrgName', keep='last')

patch_df = df.filter([
    'sbom_name',
    'Severity',
    'FixedVersion',
    'InstalledVersion',
    'PkgName'
])

patch_df["PatchStatus"] = ""

def process_row(row):
    fixed = row['FixedVersion']
    installed = row['InstalledVersion']
    if isinstance(fixed, str):
        fixed = fixed.split(",")
    if isinstance(fixed, list):
        fix = {}
        in_x,in_y,in_z = installed.split('.')
        for version in fixed:
            fix_x,fix_y,fix_z = version.split('.')
            if int(fix_x) > int(in_x):
                comment = 'MAJOR'
            elif int(fix_y) > int(in_y):
                comment = 'MINOR'
            elif int(fix_z) > int(in_z):
                comment = 'PATCH'
            else:
                comment = 'UNKNOWN'
            fix[version] = comment
        return json.dumps(fix)

patch_df['PatchStatus'] = patch_df.apply(process_row, axis=1)

pattern = r'([A-Za-z]+)(?:\.([^.]+))?(?=.sbom)'

patch_df[['OrgName', 'RepoName']] = df['sbom_name'].str.extract(pattern)

# Sort by 'sbom_name' in descending order
patch_df = patch_df.sort_values('sbom_name', ascending=False)

# Drop duplicates based on 'OrgName' and 'RepoName', keeping only the first occurrence
patch_df = patch_df.drop_duplicates(subset=['OrgName', 'RepoName'], keep='first')

if not os.path.exists("analysing_vulnerability_data/results"):
    os.makedirs("analysing_vulnerability_data/results")

patch_df.to_csv('./analysing_vulnerability_data/results/patch_report.csv')

df.to_csv('./analysing_vulnerability_data/results/vulnerability_report.csv')
df.to_json('./analysing_vulnerability_data/results/vulnerability_report.json', orient='records')

# Generate summary 

summary_df = df["Severity"].value_counts()

summary_df.to_csv('./analysing_vulnerability_data/results/summary_report.csv')
summary_df.to_json('./analysing_vulnerability_data/results/summary_report.json')

simplified_df.to_csv('./analysing_vulnerability_data/results/vulnerability_report_simplified.csv')
simplified_df.to_json('./analysing_vulnerability_data/results/vulnerability_report_simplified.json', orient='records')


